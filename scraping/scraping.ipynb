{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping\n",
    "\n",
    "This notebook contains step-by-step instructions of how to scrape together an opening database from games played at webDiplomacy and vDiplomacy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob, os\n",
    "\n",
    "from cleaning import discard_game, discard_short_games, manuals\n",
    "from games import scrape_games, load_year\n",
    "from search import scrape_search_pages\n",
    "from variants import add_variant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta-information\n",
    "\n",
    "First let us check what databases are currently available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for database in glob.glob('data/*.csv'):\n",
    "    print(database)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table `variants.csv` stores meta-information such as aliases of the variants on different webpages, what dictionary should be used for translating provinces names to short forms, and information about user id's to ignore when scraping (read: bots)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "variants = pd.read_csv('data/variants.csv')\n",
    "variants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should use the function `add_variant` from the `variants` package if you want to create a database for a new variant. It will modify the `variants.csv` table, create the table file for the variant, and create the necessary folders.\n",
    "\n",
    "`add_variant(name, powers, years=2, overwrite=False)`\n",
    "\n",
    "The parameters are:\n",
    "\n",
    "`name (string)`: Your alias for the variant.\n",
    "\n",
    "`powers (list of strings)`: The list of powers appearing in the variant.\n",
    "\n",
    "`years (integer)`: The number of game _years_ to be included in the opening analysis.\n",
    "\n",
    "`overwrite (boolean)`: Whether an existing table file should be overwritten.\n",
    "\n",
    "Below are example of how to call `add_variant` if you want to create a opening database for Germany vs. Italy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ClassicGvI\n",
    "add_variant('ClassicGvI', ['Germany', 'Italy'], years=2, overwrite=True)\n",
    "\n",
    "variants = pd.read_csv('data/variants.csv')\n",
    "variants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some information remains to be filled in. You'll have to enter the informatino manually (i.e., using pandas), see the code below. Notice that `ClassicGvI` is the variant with index 1 in the above table.\n",
    "\n",
    "The meaning of some entries are clear.\n",
    "`webDiplomacy` hold he alias for the variant on webDiplomacy.\n",
    "`vDiplomacy` holds The alias for the variant on vDiplomacy.\n",
    "`Ignore` holds a list of user indices to ignore (used to filter out bots).\n",
    "`Start` holds the starting year of the variant.\n",
    "\n",
    "The remaining two parameters are special. If you want to replace full length province names with abbreviations, then you should provide a dictionary, stored as `.json` file in the `abbreviations` folder. There is a dictionary for the classic map already. The `Dictionary` column should contain the name of the dictionary file (without the file extension). You can leave this field empty if you wish, in which case full length province names will be used.\n",
    "\n",
    "The `Messaging` parameter can be set to `'All'` or `'Gunboat'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "variants = pd.read_csv('data/variants.csv')\n",
    "\n",
    "# The variant 'ClassicGvI' has index 1 in the dataframe.\n",
    "index = 1\n",
    "\n",
    "variants.loc[index, 'webDiplomacy'] = 'ClassicGvI'\n",
    "variants.loc[index, 'vDiplomacy'] = 'ClassicGvI'\n",
    "variants.loc[index, 'Dictionary'] = 'Classic'\n",
    "variants.loc[index, 'Ignore'] = \"[108388]\"\n",
    "variants.loc[index, 'Start'] = 1901\n",
    "variants.loc[index, 'Messaging'] = 'All'\n",
    "\n",
    "variants.to_csv('data/variants.csv', index=False)\n",
    "variants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There might be other parameters that you want to filter by: phase lenght, pot size, etc. Most such parameters will be stored in the database, allowing you to filter the database at a later stage. If this is not the case, then you may submit a ticket on GitHub (or code it yourself)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping lists of games.\n",
    "The first step is to scrape lists of all games that we are interested in, which we do by scraping the search page, using\n",
    "\n",
    "`scrape_game_lists(variant, webpage, first, last)`\n",
    "\n",
    "Here, `variant` is the variant name, `webpage` is the name of the host website. The arguments  `first` and `last` are integers marking the first and last SERPs to be scraped; they allow for the list of all games to be scraped in batches.\n",
    "\n",
    "There is no issue with duplicates: if you scrape a SERP which includes a game already in your database, then that game will be ignored. Hence, if you want to scrape in batches _and_ make sure that you don't miss any games, then you should start with the first SERP. \n",
    "\n",
    "If you plan on keeping the database up to date, then you should make a note of the lowest GameID of an _active_ game; that'll be the game to look for when determining how many SERPs to scrape at your next visit. That's something which you will have to do manually.\n",
    "\n",
    "There is a 3s curtesy delay in between scrapes, as to not disturb the server too much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape_search_pages('ClassicGvI', 'webDiplomacy', 1, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning, part 1\n",
    "If you decided to have columns for _k_ in-game years in the database, then you will have to discard all games that ended before year _k_. \n",
    "You may of course discrad games that ended before year _j_, as long as _j_ is at least as big as _k_.\n",
    "\n",
    "You can use the function `discard_short_games(variant, years, dataframe)`. We pass on the variant dataframe from above, which contains the information of the starting year for the variant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "discard_short_games('ClassicGvI', 2, variants)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping game files\n",
    "Next step is to scrape the html files with orders for each games. Use the function `scrape_games(variant, webpage, m=m, verbose=verbose)`. The parameter `m` is the batch size. You can turn off the printed comments with the `verbose` parameter.\n",
    "\n",
    "There is a 3s curtesy delay in between scrapes, as to not disturb the server too much. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape_games('ClassicGvI', 'webDiplomacy', m=100, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning, part 2\n",
    "The order page scraped from vDip only shows the last 10 in-game years. That is, we cannot automatically load first two years' orders into the database if a game went on for more than 10 years. Therefore, the datafram has a `Manual` column. N.B., the current version of this function is slow and could be improved.\n",
    "\n",
    "**You must run this line even if you did not scrape from vDiplomacy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "manuals('ClassicGvI', variants)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check how many games we have which require manual entries. Ideally, you should take the time to enter them manually. But the world is not an ideal place... If the variant you have chosen typically lasts more than 10 years, then you might just have to stick with only scraping the webDip games."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/ClassicGvI.csv')\n",
    "data.Manual.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import orders into the database\n",
    "The following function reads in all orders from in-game year `year` into the database:\n",
    "\n",
    "`load_year(year, variant, webpage, variants, m=m)`\n",
    "\n",
    "Here, `m` is the batch size. Loading the database, and comparing with available games (i.e., files in the games folders), is the step which takes the most time. The number of games loaded at once does not make a big difference. That is, you might as well load all available games at once. Default is 1000 games per batch.\n",
    "\n",
    "Any `SettingWithCopyWarning` can be ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_year(1, 'ClassicGvI', 'webDiplomacy', variants)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One comment is in its place. If we look at the explicit values in the column for Spring 01 orders, then the entries _seem_ to be lists of string. In fact, they are strings. This is an artefact of the database being stored as a `.csv` file. If you want to break the strings apart into lists, to analyse separate orders, then you'll have to do some preprocessing.\n",
    "\n",
    "N.B., if you see an `NaN` when running the below code, then it is because one of you first five games has been discarded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = pd.read_csv('data/ClassicGvI.csv')\n",
    "example.ItalyS1[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning, part 3\n",
    "There are a few things (for example, bugs with the `order.php` page at webDip/vDip) which can mess up some assumptions of the functions that we use in this notebook. One example is if the game ends with only units belonging to one power. This is not a big problem: such 'outlier' games tend to be 'non-competitive'. For example, the players might deliberatly try to create a funny looking map. You'll probably find a few such game when analysing the data. The most reasonable thing is to discard those games. Use the function `discard_game(index, variant)` to discard the game which has index `index` in the database.\n",
    "\n",
    "A second problem can be the custom win conditions on vDiplomacy. This usually does not affect the functions in this notebook, but you might want to exclude such games anyways. There is no code to do this automatically at the moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "discard_game(0, 'ClassicGvI')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
